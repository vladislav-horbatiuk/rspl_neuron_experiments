\documentclass[11pt]{article}
\usepackage{float}
\usepackage{amsfonts}
\usepackage[english,ukrainian]{babel}
    \title{\textbf{Применение Recurrent Sigmoid Piecewise нейрона для прогнозирования временных рядов}}
    \date{}
    
    \addtolength{\topmargin}{-3cm}
    \addtolength{\textheight}{3cm}
\usepackage{graphicx}
\begin{document}

\maketitle
\thispagestyle{empty}

\section*{Введение}
\section*{Постановка задачи}

Имеется временной ряд ${x_1, ..., x_N}$, сгенерированный некоторым вероятностным процессом $ \{X_t\} $ с неизвестными cовместными распределениями:
$$ p(x_{t+k}, x_{t}, x_{t-1}, ..., x_{t-n}). $$
Процесс $ \{X_t\} $ может быть как стационарным так и нестационарным. Если процесс нестационарный - в общем случае данная задача прогнозирования не имеет решения, так как вероятностные распределения нестационарного ряда в теории могут "меняться"\ как угодно, и распределения в будущем могут не иметь ничего общего с распределениями, на основе которых был сгенерирован имеющийся временной ряд. Однако на практике изменение вероятностных распределений нестационарных процессов с течением времени не происходит совершенно случайным образом. Поэтому прогнозирующие модели, оцененные на имеющемся в наличии временном ряде, обычно работают удовлетворительно на протяжении определенного периода времени даже при условии нестационарности соответствующего процесса.

Необходимо использовать данный временной ряд для нахождения прогнозирующей модели вида:
$$ \hat{x}_{t+k} = f^*(x_{t}, ..., x_{t-n}), $$
которая минимизирует математическое ожидание ошибки:
$$ f^* = argmin_f \{ E_{p(x_{t+k}, x_{t}, x_{t-1}, ..., x_{t-n})} [ L(f(x_{t}, ..., x_{t-n}), x_{t+k}) ] \}, $$
где $L: \mathbb{R} \times \mathbb{R} \to \mathbb{R}_{\geq 0} $ - функция ошибки. Часто используется либо квадратическая $ L(x, y) = (x-y)^2 $ либо абсолютная ошибка $ L(x, y) = |x-y| $. Поскольку рассчитать настоящее математическое ожидание невозможно (соответствующие вероятностные распределения неизвестны), вместо него используется среднее значение функции ошибки на тестовой подвыборке временного ряда:

$$ f^* = argmin_f \{ \frac{1}{M} \sum_{t=N-k-M+1}^{N - k}{L(f(x_t, ..., x_{t-n}), x_{t+k})} \} $$.

\section*{Основные существующие методы прогнозирования}
\textbf{Линейные модели на основе ARIMA}.
\\
\textbf{Искусственные нейронные сети}.
\\
\textbf{Рекуррентные нейронные сети}.
\\
\textbf{Гибридные модели}.
\\


\section*{Recurrent Sigmoid Piecewise (RSP) нейрон}

В задачах обработки ествественного языка, таких как построение языковых моделей, автоматический перевод текста и пр. хорошо себя "зарекомендовали" рекуррентные нейронные сети на основе Long Short Term Memory (LSTM) и/или Gated Recurrent Unit (GRU) нейронов (\textbf{ДОБАВИТЬ: ссылки}). Данные нейроны имеют схожую структуру, которая позволяет уменьшить влияние проблемы затухающего/взрывающегося градиента при обучении рекуррентных моделей с использованием Backpropagation Through time (BPTT) алгоритма на длинных последовательностях. За счет этого, на практике, сети с этими нейронами более стабильны в обучении и имеют большую "точность" при работе на длинных последовательностях. LSTM-нейрон имеет следующую структуру:
\\
\\
\begin{figure}[h]
\centering
\includegraphics[scale=0.3]{/home/ivan/Downloads/LSTM3-chain.png}
\label{}
\end{figure}
\\
Полное математическое описание классического LSTM нейрона:
$$ f_t = \sigma( W_f \cdot [h_{t-1},x_t] + b_f) $$
$$ i_t = \sigma( W_i \cdot [h_{t-1},x_t] + b_i) $$
$$ \tilde{C_t} = tanh( W_C \cdot [h_{t-1},x_t] + b_C) $$
$$ C_t = f_t * C_{t-1} + i_t * \tilde{C_t} $$
$$ o_t = \sigma( W_o \cdot [h_{t-1},x_t] + b_o) $$
$$ h_t = o_t * tanh(c_t) $$
\\
\\
GRU нейрон это, по сути, упрощенная версия LSTM нейрона:
\begin{figure}[H]
\centering
\includegraphics[scale=0.50]{Downloads/LSTM3-var-GRU.png}
\label{}
\end{figure}
В данном нейроне вектор выходов $h_t$ так же "выполняет"\ роль вектора контекста, и используются следующие блоки:
\begin{itemize}
\item Блок обновления $z_t(x_t,h_{t-1};W_z)$, рассчитывающий веса в диапазоне $(0,1)$, которые применяются для рассчета нового вектора выходов (и, одновременно, контекста) $h_t$ исходя из вектора-кандидата $\tilde{h}_t$ и предыдущего вектора $h_{t-1}$
\item Блок "релевантности"\ $r_t(x_t,h_{t-1};W_r)$, рассчитывающий веса в диапазоне $(0,1)$, которые определяют "релевантность"/"важность"\ значений предыдущего выходного вектора $h_{t-1}$ при рассчете вектора-кандидата для нового выходного вектора $\tilde{h}_t$
\item Блок рассчета вектора-кандидата новых выходов $\tilde{h}_t(x_t,h_{t-1},r_t;W)$
\item Блок рассчета нового вектора выходов $h_t(h_{t-1},\tilde{h}_t,z_t)$ как взвешенной суммы соответствующих значений из предыдущего вектора $h_{t-1}$ и нового вектора-кандидата $\tilde{h}_t$, где веса для значений под индексом $i$ выбираются как $1-z_t[i]$ и $z_t[i]$ соответственно.
\end{itemize}

В данной работе предлагается новая модель рекуррентного нейрона Recurrent Sigmoid Piecewise (RSP), в основе которой лежит Sigmoid Piecewise (SP) нейрон со следующей математической моделью:
$$ SP(x;w_+,w_-,s,k)=\frac{w_+ \cdot x}{1 + e^{-k(s \cdot x)}} + \frac{w_- \cdot x}{1 + e^{k(s \cdot x)}} $$
Используя обозначение сигмоидального нейрона:
$$\sigma(x;s)=\frac{1}{1+e^{s \cdot x}}$$
и $k=1$ получаем:
$$ SP(x;w_+,w_-,s)=\sigma(x;s)(w_+ \cdot x) + \sigma(x;-s)(w_- \cdot x) $$
Используя равенство $\sigma(x;-s)=1 - \sigma(x;s)$:
$$ SP(x;w_+,w_-,s) = (1 - \sigma(x;s))(w_- \cdot x) + \sigma(x;s)(w_+ \cdot x) $$
Если вместо одного SP нейрона описывается слой из N нейронов, то вместо векторов $w_+,w_-,s$ будут использоваться матрицы $W_+,W_-,S$:
$$ SP(x;W_+,W_-, S) = (1 - \sigma(x;S)) * (W_- \cdot x) + \sigma(x;S) * (W_+ \cdot x) $$
Введя обозначения $ z = \sigma(x;S) $, $a = W_- \cdot x$ и $b = W_+ \cdot x$ получаем:
$$ SP(x) = (1 - z) * a + z * b $$
Что очень похоже на блок рассчета нового вектора выходов в нейроне GRU:
$$ h_t = (1-z_t)*h_{t-1} + z_t*\tilde{h}_t $$
Таким образом, слегка изменив SP нейрон, можно получить его рекуррентную версию, Recurrent Sigmoid Piecewise (RSP) нейрон, который принимает на вход вектор $p_t=[h_{t-1}, x_t]$ и выдает $h_t$:
$$ h_t=RSP(p_t;W_+,W_-,S) = (1-\sigma(p_t;S))*(W_- \cdot p_t) + \sigma(p_t;S)*(W_+ \cdot p_t) $$
Либо же, по аналогии с LSTM/GRU нейронами, мат. модель RSP нейрона можно записать в несколько этапов/блоков:
$$ z_t = \sigma(S \cdot [h_{t-1}, x_t]) $$
$$ q_t = W_- \cdot [h_{t-1}, x_t] $$
$$ \tilde{h}_t = W_+ \cdot [h_{t-1}, x_t] $$
$$ h_t = (1 - z_t) * q_t + z_t * \tilde{h}_t $$
\\
И представить их в виде структурной схемы:
\\
\begin{figure}[H]
\centering
\includegraphics[scale=0.3]{/home/ivan/Documents/recurrent_sigmoid_piecewise_neuron_structure.png}
\label{}
\end{figure}

Поверхностно сравнив RSP нейрон с LSTM и GRU нейронами можно сделать следующие наблюдения:
\begin{itemize}
\item Математическая модель RSP нейрона проще (используется лишь один нелинейный сигмоидальный блок) чем модели LSTM и GRU нейронов. В задаче прогнозирования временных рядов более простые модели часто предпочтительны на практике.
\item При этом, RSP так же как и LSTM и GRU нейроны позволяет забывать определенные значения в векторе контекста при необходимости.
 
\end{itemize}
  


\section*{Применение рекуррентных сетей на основе RSP нейронов для прогнозирования временных рядов}
Стандартную линейную ARMA модель можно обобщить следующим образом:
$$ X_t = \varepsilon_t + f(X_{t-1}, ..., X_{t-p}) + g(\varepsilon_{t-1},...,\varepsilon_{t-q}) ,$$
где $f: \mathbb{R}^p \to \mathbb{R}, g: \mathbb{R}^q \to \mathbb{R} $ - некоторые функции, в общем случае нелинейные. На основе этого обобщения предлагается следующая схема прогнозирования временных рядов:
\begin{figure}[H]
\centering
\includegraphics[scale=0.3]{/home/ivan/my_projects/nau_forecasting/docs/rsp_forecasting_scheme.png}
\label{}
\end{figure}
где:
\begin{itemize}
\item $x$ - входной вектор, предыдущие значения часового ряда (либо нескольких рядов)
\item \textbf{Baseline} - "базисный" метод прогнозирования, рассчитывающий начальную оценку прогноза, например линейная регрессия; соответственно $bf$ - базисное значение прогноза
\item \textbf{EP} - error prediction блок, рассчитывающий оценку ошибки прогноза $e$ базисного метода на основе: входного вектора, самого значения базисного прогноза и настоящей ошибки прогноза с предыдущего шага
\item Базисный прогноз $bf$ и оценка ошибки $e$ складываются для получения финального прогноза: $f = bf + e$
\item На следующем шаге прогнозирования также рассчитывается настоящая ошибка прогноза с предыдущего шага $ae = av - f$ и передается в блок рассчета ошибки прогноза текущего шага
\item Блок рассчета ошибки состоит из RSP нейрона и простого линейного слоя. По своей математической модели RSP нейрон может "естественным" способом рассчитывать новое значение коррекции как взвешенную сумму предыдущей ошибки и нового значения контекста.
\end{itemize}

Основным отличием данной прогнозирующей схемы от обычного использования прогнозирующей модели является блок предсказания ошибки. По сути, данный блок является нелинейной вариацией MA блока в модели ARMA. Использование этого блока позволяет схеме динамически реагировать на изменения в качестве прогноза базисной модели. Например, пускай для некоторого момента времени $ t' $ получена достаточно большая ошибка прогноза $ e_{t'} = \hat{x}_{t'} - x_{t'}, e_{t'} > 0 $, то есть прогноз модели оказался значительно больше реального значения. Одной из возможных причин может быть неожиданный для модели скачок временного ряда:
\begin{figure}[H]
\centering
\includegraphics[scale=0.25]{/home/ivan/my_projects/nau_forecasting/docs/bad_model_forecast_too_high_example1_for_dynamic_EC_block.png}
\label{}
\end{figure}

В таком случае можно ожидать, что в момент времени $ t' + 1 $ прогноз базисной модели также окажется больше, и ПО блок сможет его скорректировать. 

Преимущества данной схемы:
\begin{itemize}
\item В качестве базисного метода можно брать любой существующий метод прогнозирования, и таким образом в процессе обучения EP блок будет пытаться только улучшать прогноз базисного метода.
\item Рассчет настоящего значения ошибки прогноза с предыдущего шага (шагов) в теории дает возможность EP блоку динамически "реагировать" на изменения в качестве прогноза. Также такая схема фактически реализует нелинейную error moving average составляющую ARMA модели.
\item Мат. модель RSP нейрона естественным образом подходит для рассчета некоторой ошибки прогноза.
\item В теории возможно поэтапное обучение EP и базисного блоков - на первом этапе обучаем параметры EP блока, на втором - фиксируем их и обучаем параметры базисного блока и т.д.
\end{itemize}

\textbf{ДОБАВИТЬ:}

\begin{itemize}
  \item Использование нескольких слоев из RSP нейронов. 
  \item Использование модифицированного positional encoding.

В качестве дополнительной информации, которую можно передавать в нейронную сеть, предлагается использовать слегка модифицированный positional encoding вектор вида:
$$ p(t, k) = sin(w_k * t), k=1,2,...,K, $$
где $t$ - индекс текущего значения временного ряда, $w_1, ..., w_k$ - частоты, использующиеся для построения вектора модифицированного positional encoding. Добавление этой информации позволит модели проще предсказывать значения сезонных временных рядов.
  \item Модификация функции ошибки для уменьшение влияния проблемы затухающего градиента. Эта идея пока не полностью формализована, но мне кажется, что можно добавить определенные составляющие в функцию ошибки, которые будут влиять на параметры сети таким образом, чтобы уменьшать затухание градиентов. 


\end{itemize}

\section*{Практические примеры использования рекуррентных RSP сетей}
Для тестирования использовались показатели сердечного ритма 4 разных пациентов в разных состояниях:
\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{/home/ivan/my_projects/nau_forecasting/docs/heart_rates_data.png}
\label{}
\end{figure}

Построив "базисную" модель - оптимальный линейный предиктор получаем следующие среднеквадратические ошибки прогноза на обучающей и тестовой выборке (усредненный по всем 4 пациентам):

$$ L^{baseline}_{train} = 0.0004731 $$
$$ L^{baseline}_{test} = 0.00048 $$

Пример прогнозов линейного предиктора для одного пациента на обучающей:
\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{/home/ivan/my_projects/nau_forecasting/docs/baseline_train_forecast.png}
\label{}
\end{figure}
 и тестовой:
\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{/home/ivan/my_projects/nau_forecasting/docs/baseline_train_forecast.png}
\label{}
\end{figure}
выборках.

После "фиксации" базисного предиктора, добавления блока корекции на основе RSP нейрона и обучения его параметров получаем следующие значения среднеквадратических ошибок:
$$ L^{new}_{train} = 0.0004442 $$
$$ L^{new}_{test} = 0.00046 $$ 
что соотвествует приблизительно 5\% уменьшению среднеквадратической ошибки прогноза. 


\textbf{РАСШИРИТЬ ЭТУ ЧАСТЬ}

\section*{Выводы и дальнейшие направления работы}

\end{document}

